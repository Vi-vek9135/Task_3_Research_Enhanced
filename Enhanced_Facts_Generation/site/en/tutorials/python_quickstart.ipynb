{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vi-vek9135/Task_3_Research_Enhanced/blob/main/Enhanced_Facts_Generation/site/en/tutorials/python_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Quickstart with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/python_quickstart\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on Google AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOxMUKTxR-_j"
      },
      "source": [
        "This quickstart demonstrates how to use the Python SDK for the Gemini API, which gives you access to Google's Gemini large language models. In this quickstart, you will learn how to:\n",
        "\n",
        "1. Set up your development environment and API access to use Gemini.\n",
        "2. Generate text responses from text inputs.\n",
        "3. Generate text responses from multimodal inputs (text and images).\n",
        "4. Use Gemini for multi-turn conversations (chat).\n",
        "5. Use embeddings for large language models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9__zr1nSBpE"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You can run this quickstart in [Google Colab](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb), which runs this notebook directly in the browser and does not require additional environment configuration.\n",
        "\n",
        "Alternatively, to complete this quickstart locally, ensure that your development environment meets the following requirements:\n",
        "\n",
        "-  Python 3.9+\n",
        "-  An installation of `jupyter` to run the notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFPBKLapSCkM"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNV1e3ASJha"
      },
      "source": [
        "### Install the Python SDK\n",
        "\n",
        "The Python SDK for the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9OEoeosRTv-5"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCFF5VSTbcAR"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRC2HngneEeQ"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d10c38a5c91f"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYFrFPjSGNq"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHhsUxDTdw0W"
      },
      "source": [
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmSlTHXxb5pV"
      },
      "source": [
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ssbTMNVSMd-"
      },
      "source": [
        "## List models\n",
        "\n",
        "Now you're ready to call the Gemini API. Use `list_models` to see the available Gemini models:\n",
        "\n",
        "* `gemini-pro`: optimized for text-only prompts.\n",
        "* `gemini-pro-vision`: optimized for text-and-images prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QvvWFy08e5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "50d34159-0181-4d31-fe21-a7ad841e103c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTl5NjtrhA0J"
      },
      "source": [
        "Note: For detailed information about the available models, including their capabilities and rate limits, see [Gemini models](https://ai.google.dev/models/gemini). There are options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\n",
        "\n",
        "The `genai` package also supports the PaLM  family of models, but only the Gemini models support the generic, multimodal capabilities of the `generateContent` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfoK3I3hu6V"
      },
      "source": [
        "## Generate text from text inputs\n",
        "\n",
        "For text-only prompts, use the `gemini-pro` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2bcfnGEviwTI"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR_2A_sxk8sK"
      },
      "source": [
        "The `generate_content` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\n",
        "\n",
        "In the simplest case, you can pass a prompt string to the `GenerativeModel.generate_content` method:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_get_response(fact):\n",
        "    # Assuming model and generate_content function are defined somewhere else in your code\n",
        "    response = model.generate_content(f\"You have to generate Enhanced facts based on fact, for example Fact: Loan pending with the bank, then the Enhanced Fact: A loan is pending with a bank,  then for Query: '{fact}' \", safety_settings={'HARASSMENT':'block_none'})\n",
        "\n",
        "    prompt = textwrap.dedent(f'''\n",
        "        Fact: '{fact}'\n",
        "        Enhanced Fact: '{response.text}'\n",
        "    ''')\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "oxiIUEC5WeRO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fact = \"The accused did not create or submit forged documents to the authority\""
      ],
      "metadata": {
        "id": "WCUpJu1EaV0E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = to_get_response(fact)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "bMNCQprLaE69",
        "outputId": "1509b743-cfdb-48fa-be33-cf61783822be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fact: 'The accused did not create or submit forged documents to the authority'\n",
            "Enhanced Fact: 'Enhanced Fact: The accused is alleged to not have created or submitted forged documents to the authority'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fact = \"Loan pending with the bank.\""
      ],
      "metadata": {
        "id": "gSBbdSvwolBX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = to_get_response(fact)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "5g3JnhPnolKs",
        "outputId": "29661657-a604-40a9-93b6-d140c858a6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fact: 'Loan pending with the bank.'\n",
            "Enhanced Fact: 'Enhanced Fact: A loan is pending with a bank.'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fact = \"Physical or mental torture\""
      ],
      "metadata": {
        "id": "Uufb88HAolVo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = to_get_response(fact)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "JMZMXoewoldU",
        "outputId": "7608a838-1399-40c1-b45d-c178464534f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fact: 'Physical or mental torture'\n",
            "Enhanced Fact: 'Enhanced Fact: Physical or mental torture may be a form of mistreatment and may be a violation of human rights.'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "he-OfzBbhACQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "98681979-8c9e-4820-ddee-e9e5ae2e4df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 18.4 ms, sys: 3.64 ms, total: 22.1 ms\n",
            "Wall time: 2.15 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"You have to generate Enhanced facts based on fact, for example Fact: Loan pending with the bank, then the Enhanced Fact: A loan is pending with a bank,  then for Fact: The accused did not create or submit forged documents to the authority \", safety_settings={'HARASSMENT':'block_none'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePTT1VxdZ2mr",
        "outputId": "ad7a80b7-1663-4cf3-cdfc-052f5e75f6f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced Fact: The accused did not create or submit fabricated documents to the authority\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbrR-n_qlpFd"
      },
      "source": [
        "In simple cases, the `response.text` accessor is all you need. To display formatted Markdown text, use the `to_markdown` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G-zBkueElVEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "a6df8597-46fc-4768-b072-b20b974d89a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Enhanced Fact: The accused did not create or submit fabricated documents to the authority"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "python_quickstart.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}