{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vi-vek9135/Task_3_Research_Enhanced/blob/main/Researchbook_Name_Generation/site/en/tutorials/python_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Quickstart with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/python_quickstart\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on Google AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOxMUKTxR-_j"
      },
      "source": [
        "This quickstart demonstrates how to use the Python SDK for the Gemini API, which gives you access to Google's Gemini large language models. In this quickstart, you will learn how to:\n",
        "\n",
        "1. Set up your development environment and API access to use Gemini.\n",
        "2. Generate text responses from text inputs.\n",
        "3. Generate text responses from multimodal inputs (text and images).\n",
        "4. Use Gemini for multi-turn conversations (chat).\n",
        "5. Use embeddings for large language models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9__zr1nSBpE"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You can run this quickstart in [Google Colab](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb), which runs this notebook directly in the browser and does not require additional environment configuration.\n",
        "\n",
        "Alternatively, to complete this quickstart locally, ensure that your development environment meets the following requirements:\n",
        "\n",
        "-  Python 3.9+\n",
        "-  An installation of `jupyter` to run the notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFPBKLapSCkM"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNV1e3ASJha"
      },
      "source": [
        "### Install the Python SDK\n",
        "\n",
        "The Python SDK for the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9OEoeosRTv-5"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCFF5VSTbcAR"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRC2HngneEeQ"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d10c38a5c91f"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYFrFPjSGNq"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHhsUxDTdw0W"
      },
      "source": [
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmSlTHXxb5pV"
      },
      "source": [
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ssbTMNVSMd-"
      },
      "source": [
        "## List models\n",
        "\n",
        "Now you're ready to call the Gemini API. Use `list_models` to see the available Gemini models:\n",
        "\n",
        "* `gemini-pro`: optimized for text-only prompts.\n",
        "* `gemini-pro-vision`: optimized for text-and-images prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QvvWFy08e5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f709dfa4-7a60-45cb-e87c-6ee79dbd1412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTl5NjtrhA0J"
      },
      "source": [
        "Note: For detailed information about the available models, including their capabilities and rate limits, see [Gemini models](https://ai.google.dev/models/gemini). There are options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\n",
        "\n",
        "The `genai` package also supports the PaLM  family of models, but only the Gemini models support the generic, multimodal capabilities of the `generateContent` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfoK3I3hu6V"
      },
      "source": [
        "## Generate text from text inputs\n",
        "\n",
        "For text-only prompts, use the `gemini-pro` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2bcfnGEviwTI"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR_2A_sxk8sK"
      },
      "source": [
        "The `generate_content` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\n",
        "\n",
        "In the simplest case, you can pass a prompt string to the `GenerativeModel.generate_content` method:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_get_response(query):\n",
        "    # Assuming model and generate_content function are defined somewhere else in your code\n",
        "    response = model.generate_content(f\"You have to generate Research book name based on query: for example Query: Cheque Bounce then the Research Book Name may be: Cheque Bounce Chronicles: Legal Perspectives and Summaries,  then for Query: '{query}' \",safety_settings={'HARASSMENT':'block_none'})\n",
        "\n",
        "    prompt = textwrap.dedent(f'''\n",
        "        Query: '{query}'\n",
        "        Research book name: '{response.text}'\n",
        "    ''')\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "oxiIUEC5WeRO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Murder\""
      ],
      "metadata": {
        "id": "WCUpJu1EaV0E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = to_get_response(query)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "bMNCQprLaE69",
        "outputId": "2f7c1984-d4fe-41f9-df6a-dec17b355aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        Query: 'Murder'\n",
            "        Research book name: '**Query**: ''''\n",
            "\n",
            "**Research Book Name**: Research Book Names on ''\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Siblings Murder\""
      ],
      "metadata": {
        "id": "YY2wxJ2LtfBe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = to_get_response(query)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "wCCR0NbqtfI_",
        "outputId": "fddbb39e-72a5-40ac-abc9-12458f1f3498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: 'Siblings Murder'\n",
            "Research book name: 'Siblingcide Syndrome: A Psychological and Forensic Examination'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Is a last will considered the final will of a person?\""
      ],
      "metadata": {
        "id": "ShP-PDe5tfMq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = to_get_response(query)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "B5uUaRR9tfXF",
        "outputId": "d04c1921-1f31-4e94-d36f-1ca92e3591c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: 'Is a last will considered the final will of a person?'\n",
            "Research book name: '**Research Book Name:** The Enforceability of Last Wills: A Comprehensive Guide to Testamentary Law'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he-OfzBbhACQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b5230d6c-ad95-4028-d171-0600c69280ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 36.7 ms, sys: 3.35 ms, total: 40.1 ms\n",
            "Wall time: 2.21 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"You have to generate Research book name based on query: for example Query: Cheque Bounce then the\tResearch Book Name may be :Cheque Bounce Chronicles: Legal Perspectives and Summaries,  then for Query: Sibling Murder \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePTT1VxdZ2mr",
        "outputId": "3a02eb1d-17be-4e5c-c219-82da4de46909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Research Book Name based on query:\n",
            "\n",
            "for query: Cheque\n",
            "Book Name: Cheque: Law, Policy, and Global Practices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbrR-n_qlpFd"
      },
      "source": [
        "In simple cases, the `response.text` accessor is all you need. To display formatted Markdown text, use the `to_markdown` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-zBkueElVEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "9169db49-0e5b-416e-dafd-15144f5bd265"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Research Book Name: Legally Binding Last Wills: A Comprehensive Guide to Final Testamentary Documents"
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "We-U5cKcaMYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "python_quickstart.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}